@article{van Lieshout:2020,
author = {van Lieshout, Colin and van Oeveren, Kees and van Emmerik, Tim and Postma, Eric},
title = {Automated River Plastic Monitoring Using Deep Learning and Cameras},
journal = {Earth and Space Science},
volume = {7},
number = {8},
pages = {e2019EA000960},
keywords = {plastic pollution, object detection, automated monitoring, deep learning, artificial intelligence, river plastic},
doi = {https://doi.org/10.1029/2019EA000960},
url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2019EA000960},
eprint = {https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2019EA000960},
note = {e2019EA000960 10.1029/2019EA000960},
abstract = {Abstract Quantifying plastic pollution on surface water is essential to understand and mitigate the impact of plastic pollution to the environment. Current monitoring methods such as visual counting are labor intensive. This limits the feasibility of scaling to long-term monitoring at multiple locations. We present an automated method for monitoring plastic pollution that overcomes this limitation. Floating macroplastics are detected from images of the water surface using deep learning. We perform an experimental evaluation of our method using images from bridge-mounted cameras at five different river locations across Jakarta, Indonesia. The four main results of the experimental evaluation are as follows. First, we realize a method that obtains a reliable estimate of plastic density (68.7\% precision). Our monitoring method successfully distinguishes plastics from environmental elements, such as water surface reflection and organic waste. Second, when trained on one location, the method generalizes well to new locations with relatively similar conditions without retraining (≈50\% average precision). Third, generalization to new locations with considerably different conditions can be boosted by retraining on only 50 objects of the new location (improving precision from ≈20\% to ≈42\%). Fourth, our method matches visual counting methods and detects ≈35\% more plastics, even more so during periods of plastic transport rates of above 10 items per meter per minute. Taken together, these results demonstrate that our method is a promising way of monitoring plastic pollution. By extending the variety of the data set the monitoring method can be readily applied at a larger scale.},
year = {2020}
}

@misc{WADE AI:2020,
  author = {K. Kerge, W. Cowger, K. Haamer, K. Ehala, K. Kivistik, T. Tammiste, M. Vares},
  title = {WADE AI Trash Detection},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/letsdoitworld/wade-ai}
}

@misc{Wuu:2018,
  author = {S. Wuu},
  title = {Litter Detection Tensorflow},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/isaychris/litter-detection-tensorflow}
}






@ARTICLE{Lynch:2018,
  title    = "{OpenLitterMap.com} -- Open Data on Plastic Pollution with
              Blockchain Rewards (Littercoin)",
  author   = "Lynch, Se{\'a}n",
  abstract = "OpenLitterMap rewards users with Littercoin for producing open
              data on litter. Open data on the geospatial characteristics of
              litter provide means of invoking and evaluating responses to
              plastic pollution. OpenLitterMap currently works as a web app on
              all devices with native mobile apps in development. The stack
              includes the integration of the Laravel PHP Framework on the
              backend; Vue for frontend reactivity; NativeScript-Vue for mobile
              apps; Bulma for CSS; Leaflet for web-mapping; Turf.js for
              geospatial analysis; the Ethereum Blockchain for tokenization;
              Stripe; ChartJS; AWS; and more. Anywhere from a single cigarette
              butt to the contents of an entire beach or street clean can be
              logged in a single geotagged photo. Alternatively, a simple index
              may be used if litter is incalculable. The open data includes an
              increasing 100+ pre-defined types of litter; 20+ corporate
              brands; verification status; coordinates; timestamp; phone model;
              the latest OpenStreetMap address at each location; and the litter
              presence as a Boolean. To date, 100\% of all submitted data (~
              8200 photos, ~ 28,000 litter from over 150 contributors) has been
              manually verified which is being used to develop machine learning
              algorithms.",
  journal  = "Open Geospatial Data, Software and Standards",
  volume   =  3,
  number   =  1,
  pages    = "6",
  month    =  jun,
  year     =  2018
}

@article{Majchrowska:2022,
title = {Deep learning-based waste detection in natural and urban environments},
journal = {Waste Management},
volume = {138},
pages = {274-284},
year = {2022},
issn = {0956-053X},
doi = {https://doi.org/10.1016/j.wasman.2021.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0956053X21006474},
author = {Sylwia Majchrowska and Agnieszka Mikołajczyk and Maria Ferlin and Zuzanna Klawikowska and Marta A. Plantykow and Arkadiusz Kwasigroch and Karol Majek},
keywords = {Object detection, Semi-supervised learning, Waste classification benchmarks, Waste detection benchmarks, Waste localization, Waste recognition},
abstract = {Waste pollution is one of the most significant environmental issues in the modern world. The importance of recycling is well known, both for economic and ecological reasons, and the industry demands high efficiency. Current studies towards automatic waste detection are hardly comparable due to the lack of benchmarks and widely accepted standards regarding the used metrics and data. Those problems are addressed in this article by providing a critical analysis of over ten existing waste datasets and a brief but constructive review of the existing Deep Learning-based waste detection approaches. This article collects and summarizes previous studies and provides the results of authors’ experiments on the presented datasets, all intended to create a first replicable baseline for litter detection. Moreover, new benchmark datasets detect-waste and classify-waste are proposed that are merged collections from the above-mentioned open-source datasets with unified annotations covering all possible waste categories: bio, glass, metal and plastic, non-recyclable, other, paper, and unknown. Finally, a two-stage detector for litter localization and classification is presented. EfficientDet-D2 is used to localize litter, and EfficientNet-B2 to classify the detected waste into seven categories. The classifier is trained in a semi-supervised fashion making the use of unlabeled images. The proposed approach achieves up to 70% of average precision in waste detection and around 75% of classification accuracy on the test dataset. The code and annotations used in the studies are publicly available online11https://github.com/wimlds-trojmiasto/detect-waste..}
}

@misc{Proença:2020,
  doi = {10.48550/ARXIV.2003.06975},
  url = {https://arxiv.org/abs/2003.06975},
  author = {Proença, Pedro F and Simões, Pedro},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {TACO: Trash Annotations in Context for Litter Detection},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


